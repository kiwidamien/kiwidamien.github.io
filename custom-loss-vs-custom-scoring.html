<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Custom Loss vs Custom Scoring</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
  <link href="https://kiwidamien.github.io" rel="canonical" />

  <!-- Feed -->

  <link href="https://kiwidamien.github.io/theme/css/style.css" type="text/css" rel="stylesheet" />
  <link href="https://kiwidamien.github.io/theme/css/collapse.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="https://kiwidamien.github.io/theme/css/code_blocks/monokai.css" rel="stylesheet">
  
  <link href="https://kiwidamien.github.io/theme/css/code_blocks/notebook.css" rel="stylesheet">

    <!-- CSS specified by the user -->
    <link href="https://kiwidamien.github.io/assets/css/mystyle.css" type="text/css" rel="stylesheet" />


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->


    <link href="https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html" rel="canonical" />

        <meta name="description" content="Scikit learn grid search functions include a scoring parameter. Scorers allow us to compare different trained models. Models try to...">

        <meta name="author" content="Damien Martin">

        <meta name="tags" content="machine learning">
        <meta name="tags" content="technical">
        <meta name="tags" content="metrics">

        <meta property="og:locale" content="" />
    <meta property="og:site_name" content="Stacked Turtles" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Stacked Turtles" />
    <meta property="og:description" content="View the blog." />
    <meta property="og:url" content="https://kiwidamien.github.io" />
      <meta property="og:image" content="https://kiwidamien.github.io/assets/images/tools.png" />

  <meta property="og:type" content="article">
            <meta property="article:author" content="https://kiwidamien.github.io/author/damien-martin.html">
  <meta property="og:url" content="https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html">
  <meta property="og:title" content="Custom Loss vs Custom Scoring">
  <meta property="article:published_time" content="2019-07-28 11:20:00-07:00">
            <meta property="og:description" content="Scikit learn grid search functions include a scoring parameter. Scorers allow us to compare different trained models. Models try to...">

            <meta property="og:image" content="https://kiwidamien.github.io/assets/images/tools.png">
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>
          <li><a href="https://kiwidamien.github.io/about.html" role="presentation">About this blog</a></li>
          <li><a href="http://slashdot.org" role="presentation">slashdot</a></li>
          <li><a href="https://thisismetis.com" role="presentation">metis</a></li>
          <li><a href="https://stackoverflow.com" role="presentation">stackoverflow</a></li>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="https://kiwidamien.github.io" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Custom Loss vs Custom Scoring</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="https://kiwidamien.github.io/author/damien-martin.html">Damien martin</a>
            | <time datetime="Sun 28 July 2019">Sun 28 July 2019</time>
        </span>
        <span class="post-meta">
          Filed under: <b><a href="https://kiwidamien.github.io/category/data-science.html">Data science</a></b>
        </span>

        <!-- TODO : Modified check -->


    <div class="post-cover cover" style="background-image: url('assets/images/tools.png')">

</div>
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <p>When fitting data, we might decide we want to find the smallest mean squared error (MSE) or (equivalently) maximize the coefficient of determination <span class="math">\(R^2\)</span>. We can use <code>LinearRegression</code>, <code>Ridge</code>, or <code>Lasso</code> that optimize on finding the smallest MSE, and this matches the thing we want to optimize.</p>
<p>While common, MSE isn't necessarily the best error metric for your problem. Other examples are</p>
<ul>
<li><em>Mean absolute error (MAE)</em>: doesn't penalize outliers as much as MSE, generally more robust prediction.</li>
<li><em>Huber loss</em>: gives MSE for points "close" to a certain distance away, and MAE after that. MSE is not sensitive to small errors (for small <span class="math">\(x\)</span>, <span class="math">\(x^2\)</span> is smaller than <span class="math">\(x\)</span>) but transforms to linear loss far away.</li>
<li><em>Hinge loss</em>: gives no penalty for points "close enough" to the prediction. Outside of the no penalty region (typically called the margin) the penalty increases linearly. This is what SVMs use when doing regression.</li>
<li><em>Quantile Loss</em>: Maybe underestimating is worse than overestimating (e.g. when predicting how much to buy). You would like an error metric that gives a higher penalty for getting an answer that is too low.</li>
</ul>
<p>When looking at the documentation for Ridge and Lasso, you won't find a scoring parameter. You might think that you could optimize for mean absolute error in the following way:</p>
<div class="highlight"><pre><span></span><span class="c1"># Doesn&#39;t this minimize mean absolute error?</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
<span class="n">rcv</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>


<p>Not really. There are two different things happening:</p>
<ul>
<li>For <em>each</em> value in <code>alphas</code> we are solving a Ridge regression, which attempts to minimize the MSE (not MAE). This gives us a model that gets the best coefficients for minimizing the MSE with this value for the regularization parameter.</li>
<li>Then we compare the mean <em>absolute</em> error in the predictions for the five different models we made, and pick the one with the lowest MAE.</li>
</ul>
<p>So we only apply the <code>scoring</code> parameter when choosing between models, <em>not</em> when fitting the individual models themselves.</p>
<p>This can be subtle, so it is worth distinguishing the two concepts:</p>
<ul>
<li><strong>Loss:</strong> The metric that your fitting method optimizes for a given model with all hyperparameters set.</li>
<li><strong>Scoring:</strong> The metric used to choose between your optimized model (i.e. how you pick the best hyperparameters).</li>
</ul>
<p>If you are trying to minimize the MAE, you would ideally want to have MAE as your loss (so each model has the smallest possible MAE, given the hyperparameters) <em>and</em> have MAE as your scoring function (so you pick the best hyperparameters). If you use MSE as your loss, and MAE as your scoring, you are unlikely to find the best answer.</p>
<p>Scikit-learn makes it very easy to provide your own custom score function, but not to provide your own loss functions. In this <a href="">Github issue</a>, Andreas Muller has stated that this is not something that Scikit-learn will support. While it is clearly useful, function calls in Python are slow. A loss function can be called thousands of times on a single model to find its parameters (the number of tiems called depends on <code>max_tol</code> and <code>max_iterations</code> parameters to the estimators). A scoring function, on the other hand, is only called once per model to do a final comparison between models.</p>
<p>We will never be able to have Ridge or Lasso support even a simple error such as Mean Absolute Error. For this particular loss, you <em>can</em> use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html"><code>SGDRegressor</code></a> to minimize MAE. For quantile loss, or Mean Absolute Percent Error (MAPE) you either have to use a different package such as <code>statsmodels</code> or roll-your-own.</p>
<h2>An example where having different loss and scoring is reasonable.</h2>
<p>It might seem shocking that loss and scoring are different. After all, if we are going to optimize for something, wouldn't it make sense to optimize for it throughout? While this is generally true, we are far more comfortable with the idea that loss and scoring being different in classification problems. Consider a classifier for determining if someone had a disease, and we are aiming for high recall (i.e. we would rather make sure we find everyone with the disease) </p>
<div class="highlight"><pre><span></span><span class="c1"># Here are some parameters to search over</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
  <span class="o">....</span>
<span class="p">}</span>

<span class="n">rf_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;recall&#39;</span><span class="p">)</span>
<span class="n">rf_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>


<p>It is possible to get 100% recall by simply predicting everyone has the disease. That is <em>not</em> what the code above does. Instead, for each combination of hyperparameters we train a random forest in the usual way (minimizing the entropy or Gini score). Once we have all of those different trained models, <em>then</em> we compare their recall and select the best one.</p>
<p>This isn't fundamentally any different from what is happening when we find coefficients using MSE and then select the model with the lowest MAE, instead of using MAE as both the loss and the scoring. The difference is that recall is a bad loss function because it is trivial to optimize. In classification, we are a lot happier using a loss and a metric that are different.</p>
<p>(I would put forward an opinion that because recall is a bad <em>loss</em>, it is also a bad <em>metric</em>. If I would not optimize against recall directly -- and I shouldn't -- it is because it is pathelogical, and so I shouldn't use it to select between my models either. Instead, in a given problem, I should more carefully consider the trade-offs between false positives and false negatives, and use that to pick an appropriate scoring method. I also believe I am in the minority in this view that recall is a pathelogical score, so it is probably best you don't repeat this point of view while on an interview.)</p>
<h2>Making a custom score</h2>
<p>Now that we understand the difference between a loss and a scorer, how do we implement a custom score? The first step is to see if we need to, or if it is already implemented for us. We can find a list of build-in scores with the following code:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn</span>
<span class="k">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SCORERS</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>


<p>This lists the 35 (at the time of writing) different scores that sklearn already recognizes.</p>
<p>If the score you want isn't on that list, then you can build a custom scorer. The easiest way to do this is to make an ordinary python function <code>my_score_function(y_true, y_predict, **kwargs)</code>, then use sklearn's <code>make_scorer</code> to create an object with all the properties that sklearn's grid search expects. This sounds complicated, but let's build mean absolute error as a scorer to see how it would work. Note this scorer is already built-in, so in practice we would use that, but this is an easy to understand scorer:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">mean_abs_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_predict</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">mean_abs_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">mean_abs_error</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>


<p>The <code>make_scorer</code> function takes two arguments: the function you want to transform, and a statment about whether you want to maximize the score (like accuracy and <span class="math">\(R^2\)</span>) or minimize it (like MSE or MAE). In the standard implementation, it is assumed that the a higher score is better, which is why we see the functions we want to minimize appear in the negative form, such as <code>neg_mean_absolute_error</code>: minimizing the mean absolute error is the same as maximizing the <em>negative</em> of the mean absolute error. The <code>make_scorer</code> function allows us to specify directly whether we should maximize or minimize.</p>
<p>We can now use the scorer in cross-validation like so:</p>
<div class="highlight"><pre><span></span><span class="c1"># This was our original way of using cross-validation using MAE:</span>
<span class="c1"># Note we would use the scoring parameter in GridSearchCV or others</span>
<span class="n">rcv</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># This is equivalent, using our custom scorer</span>
<span class="n">rcv</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">mean_abs_scorer</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>


<h3>Unfortunate choice of terminology</h3>
<p>In the scikit-learn documentation, they make an unfortunate distinction is made between scores you attempt to maximize, and scores you attempt to minimize. They call a score you try to maximize a "score", and a score you try to minimize a "loss" in <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html">this part of the documentation</a> when describing <code>greater_is_better</code>.</p>
<p>I am not using those terms the same way here! It isn't you that is confused! I don't use the same terminology as sklearn for a few reasons:</p>
<ul>
<li>The function described, <code>make_scorer</code> should make ... scorers. It seems perverse to say some scorers return scores, and some return losses, which sklearn tries to do. This scorer is a score, and this scorer is a loss is just far too confusing.</li>
<li>The term loss is commonly used in fitting algorithms in literate. This gives a nice distinction between a loss (used when fitting) and a score (used when choosing between fit models). Sklearn's usage "uses up" a perfectly good term "loss" instead of just talking about a score we are trying to minimize.</li>
</ul>
<h3>Implementing MAPE</h3>
<p>The scorer we implemented about wasn't that useful, as we could already use the predefined <code>'neg_mean_absolute_error'</code> string to accomplish the same goal. Let's implement a new score, mean absolute percentage error (MAPE), that isn't predefined in sklearn. The definition of MAPE is </p>
<div class="math">$$ \text{MAPE} = \frac{1}{n}\sum_{i=1}^n |\text{\% error in }y_{\text{predict, i}}| = \frac{1}{n}\sum_i \frac{|y_{\text{true, i}} - y_{\text{predict, i}}|}{|y_{\text{true, i}}|} $$</div>
<p>In code, this is</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mape</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">):</span>
  <span class="c1"># Note this blows up if y_true = 0</span>
  <span class="c1"># Ignore for demo -- in some sense an unsolvable</span>
  <span class="c1"># problem with MAPE as an error metric</span>
  <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
  <span class="n">y_predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_predict</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_predict</span><span class="p">)</span><span class="o">/</span><span class="n">y_true</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">mape_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">mape</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>


<h2>Making a custom loss</h2>
<p>Making a custom loss is a lot harder, and I have devoted a separate (upcoming) <a href="/custom_loss.html">post</a> to it. The simple approaches are</p>
<ul>
<li>Write your own estimator in sklearn. <a href="https://alex.miller.im/posts/linear-model-custom-loss-function-regularization-python/">Alex Millar</a> has done this in one of his posts, which my article borrows from.</li>
<li>Write a custom loss in Keras. Neural nets can be used for large networks with interpretability problems, but we can also use just a single neuron to get linear models with completely custom loss functions.</li>
</ul>
<h2>Summary</h2>
<ul>
<li>The loss that is used during the <code>fit</code> parameter should be thought of as part of the model in scikit-learn. Because of the expense of making function calls, scikit-learn won't be supporting custom losses.</li>
<li>In particular, <code>Ridge</code> and <code>Lasso</code> will always minimize MSE (or equivalently maximize <span class="math">\(R^2\)</span>).</li>
<li>You can minimize MAE using <code>SGDRegressor</code>.</li>
<li>Custom losses require looking outside sklearn (e.g. at Keras) or writing your own estimator.</li>
<li>Model <em>scoring</em> allows you to select between different trained models. Scikit-learn makes custom scoring very easy.</li>
<li>The difference is a custom score is called once per model, while a custom loss would be called thousands of times per model.</li>
<li>The <code>make_scorer</code> documentation unfortunately uses "score" to mean a metric where bigger is better (e.g. <span class="math">\(R^2\)</span>, accuracy, recall, <span class="math">\(F_1\)</span>) and "loss" to mean a metric where smaller is better (e.g. MSE, MAE, log-loss). This usage of loss <em>isn't</em> the same as the way it is used in this article.</li>
</ul>
<h2>References</h2>
<ul>
<li>The <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html"><code>make_scorer</code></a> documentation.</li>
<li>The <a href="https://github.com/scikit-learn/scikit-learn/issues/1701">github issue</a> where the community decided against passing custom loss functions.</li>
<li>Article on implementing a <a href="/custom_loss.html">custom loss</a> (to come)</li>
<li>Alex Miller's <a href="https://alex.miller.im/posts/linear-model-custom-loss-function-regularization-python/">customer estimator</a> for implementing a custom loss (in this case MAPE: Mean Absolute Percentage Error)</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </section>

            <section class="post-info">
                <div class=a"post-share">
                    <a class="twitter" href="https://twitter.com/share?text=Custom Loss vs Custom Scoring&amp;url=https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="https://kiwidamien.github.io/tag/machine-learning.html">machine learning</a><a href="https://kiwidamien.github.io/tag/technical.html">technical</a><a href="https://kiwidamien.github.io/tag/metrics.html">metrics</a>                </aside>

                <div class="clear"></div>

                <aside class="post-author">
                        <figure class="post-author-avatar">
                            <img src="../assets/images/avatar.png" alt="Damien martin" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="https://kiwidamien.github.io/author/damien-martin.html">Damien martin</a></h4>
                            <p class="post-author-about">I am a data scientist with an interest in what drives the world. Background in Physics, Math, and Computer Science. Interested in Algorithms, Games, Books, Music, and Martial Arts. That is, when I am not off taking pictures somewhere! </p>
                            <span class="post-author-location"><i class="ic ic-location"></i> USA</span>
                            <span class="post-author-website"><a href="http://kiwidamien.github.io"><i class="ic ic-link"></i> Website</a></span>
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <a class="post-nav-prev" href="https://kiwidamien.github.io/changing_definitions.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-right"></i>
                                <h2 class="post-nav-title">Pros and Cons of Changing Definitions</h2>
                            <p class="post-nav-excerpt">A definition cannot be wrong, but it can fail to be useful. Can you repurpose a...</p>
                        </section>
                    </a>
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>
  
  </section>

  <script type="text/javascript" src="https://kiwidamien.github.io/theme/js/script.js"></script>

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-131671634-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>

</html>