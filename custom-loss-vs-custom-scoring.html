<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Custom Loss vs Custom Scoring</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
  <link href="https://kiwidamien.github.io" rel="canonical" />

  <!-- Feed -->

  <link href="https://kiwidamien.github.io/theme/css/style.css" type="text/css" rel="stylesheet" />
  <link href="https://kiwidamien.github.io/theme/css/collapse.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="https://kiwidamien.github.io/theme/css/code_blocks/monokai.css" rel="stylesheet">
  
  <link href="https://kiwidamien.github.io/theme/css/code_blocks/notebook.css" rel="stylesheet">

    <!-- CSS specified by the user -->
    <link href="https://kiwidamien.github.io/assets/css/mystyle.css" type="text/css" rel="stylesheet" />


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->


    <link href="https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html" rel="canonical" />

        <meta name="description" content="Scikit learn grid search functions include a scoring parameter. Scorers allow us to compare different trained models. Models try to...">

        <meta name="author" content="Damien Martin">

        <meta name="tags" content="machine learning">
        <meta name="tags" content="technical">
        <meta name="tags" content="metrics">

        <meta property="og:locale" content="" />
    <meta property="og:site_name" content="Stacked Turtles" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Stacked Turtles" />
    <meta property="og:description" content="View the blog." />
    <meta property="og:url" content="https://kiwidamien.github.io" />
      <meta property="og:image" content="https://kiwidamien.github.io/assets/images/tools.png" />

  <meta property="og:type" content="article">
            <meta property="article:author" content="https://kiwidamien.github.io/author/damien-martin.html">
  <meta property="og:url" content="https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html">
  <meta property="og:title" content="Custom Loss vs Custom Scoring">
  <meta property="article:published_time" content="2019-07-28 11:20:00-07:00">
            <meta property="og:description" content="Scikit learn grid search functions include a scoring parameter. Scorers allow us to compare different trained models. Models try to...">

            <meta property="og:image" content="https://kiwidamien.github.io/assets/images/tools.png">
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>
          <li><a href="https://kiwidamien.github.io/about.html" role="presentation">About this blog</a></li>
          <li><a href="http://slashdot.org" role="presentation">slashdot</a></li>
          <li><a href="https://thisismetis.com" role="presentation">metis</a></li>
          <li><a href="https://stackoverflow.com" role="presentation">stackoverflow</a></li>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="https://kiwidamien.github.io" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Custom Loss vs Custom Scoring</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="https://kiwidamien.github.io/author/damien-martin.html">Damien martin</a>
            | <time datetime="Sun 28 July 2019">Sun 28 July 2019</time>
        </span>
        <span class="post-meta">
          Filed under: <b><a href="https://kiwidamien.github.io/category/data-science.html">Data science</a></b>
        </span>

        <!-- TODO : Modified check -->


    <div class="post-cover cover" style="background-image: url('assets/images/tools.png')">

</div>
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <p>When fitting data, we might decide we want to find the smallest mean squared error (MSE) or (equivalently) maximize the coefficient of determination <span class="math">\(R^2\)</span>. We can use <code>LinearRegression</code>, <code>Ridge</code>, or <code>Lasso</code> that optimize on finding the smallest MSE, and this matches the thing we want to optimize.</p>
<p>While common, MSE isn't necessarily the best error metric for your problem. Other examples are</p>
<ul>
<li><em>Mean absolute error (MAE)</em>: doesn't penalize outliers as much as MSE, generally more robust prediction.</li>
<li><em>Huber loss</em>: gives MSE for points "close" to a certain distance away, and MAE after that. MSE is not sensitive to small errors (for small <span class="math">\(x\)</span>, <span class="math">\(x^2\)</span> is smaller than <span class="math">\(x\)</span>) but transforms to linear loss far away.</li>
<li><em>Hinge loss</em>: gives no penalty for points "close enough" to the prediction. Outside of the no penalty region (typically called the margin) the penalty increases linearly. This is what SVMs use when doing regression.</li>
<li><em>Quantile Loss</em>: Maybe underestimating is worse than overestimating (e.g. when predicting how much to buy). You would like an error metric that gives a higher penalty for getting an answer that is too low.</li>
</ul>
<p>When looking at the documentation for Ridge and Lasso, you won't find a scoring parameter. You might think that you could optimize for mean absolute error in the following way:</p>
<div class="highlight"><pre><span></span><span class="c1"># Doesn&#39;t this minimize mean absolute error?</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
<span class="n">rcv</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>


<p>Not really. There are two different things happening:</p>
<ul>
<li>For <em>each</em> value in <code>alphas</code> we are solving a Ridge regression, which attempts to minimize the MSE (not MAE). This gives us a model that gets the best coefficients for minimizing the MSE with this value for the regularization parameter.</li>
<li>Then we compare the mean <em>absolute</em> error in the predictions for the five different models we made, and pick the one with the lowest MAE.</li>
</ul>
<p>So we only apply the <code>scoring</code> parameter when choosing between models, <em>not</em> when fitting the individual models themselves.</p>
<p>This can be subtle, so it is worth distinguishing the two concepts:</p>
<ul>
<li><strong>Loss:</strong> The metric that your fitting method optimizes for a given model with all hyperparameters set.</li>
<li><strong>Scoring:</strong> The metric used to choose between your optimized model (i.e. how you pick the best hyperparameters).</li>
</ul>
<p>If you are trying to minimize the MAE, you would ideally want to have MAE as your loss (so each model has the smallest possible MAE, given the hyperparameters) <em>and</em> have MAE as your scoring function (so you pick the best hyperparameters). If you use MSE as your loss, and MAE as your scoring, you are unlikely to find the best answer.</p>
<p>Scikit-learn makes it very easy to provide your own custom score function, but not to provide your own loss functions. In this <a href="">Github issue</a>, Andreas Muller has stated that this is not something that Scikit-learn will support. While it is clearly useful, function calls in Python are slow. A loss function can be called thousands of times on a single model to find its parameters (the number of tiems called depends on <code>max_tol</code> and <code>max_iterations</code> parameters to the estimators). A scoring function, on the other hand, is only called once per model to do a final comparison between models.</p>
<p>We will never be able to have Ridge or Lasso support even a simple error such as Mean Absolute Error. For this particular loss, you <em>can</em> use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html"><code>SGDRegressor</code></a> to minimize MAE. For quantile loss, or Mean Absolute Percent Error (MAPE) you either have to use a different package such as <code>statsmodels</code> or roll-your-own.</p>
<h2>An example where having different loss and scoring is reasonable.</h2>
<p>It might seem shocking that loss and scoring are different. After all, if we are going to optimize for something, wouldn't it make sense to optimize for it throughout? While this is generally true, we are far more comfortable with the idea that loss and scoring being different in classification problems. Consider a classifier for determining if someone had a disease, and we are aiming for high recall (i.e. we would rather make sure we find everyone with the disease) </p>
<div class="highlight"><pre><span></span><span class="c1"># Here are some parameters to search over</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
  <span class="o">....</span>
<span class="p">}</span>

<span class="n">rf_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;recall&#39;</span><span class="p">)</span>
<span class="n">rf_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>


<p>It is possible to get 100% recall by simply predicting everyone has the disease. That is <em>not</em> what the code above does. Instead, for each combination of hyperparameters we train a random forest in the usual way (minimizing the entropy or Gini score). Once we have all of those different trained models, <em>then</em> we compare their recall and select the best one.</p>
<p>This isn't fundamentally any different from what is happening when we find coefficients using MSE and then select the model with the lowest MAE, instead of using MAE as both the loss and the scoring. The difference is that recall is a bad loss function because it is trivial to optimize. In classification, we are a lot happier using a loss and a metric that are different.</p>
<p>(I would put forward an opinion that because recall is a bad <em>loss</em>, it is also a bad <em>metric</em>. If I would not optimize against recall directly -- and I shouldn't -- it is because it is pathelogical, and so I shouldn't use it to select between my models either. Instead, in a given problem, I should more carefully consider the trade-offs between false positives and false negatives, and use that to pick an appropriate scoring method. I also believe I am in the minority in this view that recall is a pathelogical score, so it is probably best you don't repeat this point of view while on an interview.)</p>
<h2>Making a custom score</h2>
<p>Now that we understand the difference between a loss and a scorer, how do we implement a custom score? The first step is to see if we need to, or if it is already implemented for us.</p>
<h2>Making a custom loss</h2>
<p>Making a custom loss is a lot harder, and I have devoted a separate (upcoming) <a href="/custom_loss.html">post</a> to it. The simple approaches are</p>
<ul>
<li>Write your own estimator in sklearn. <a href="https://alex.miller.im/posts/linear-model-custom-loss-function-regularization-python/">Alex Millar</a> has done this in one of his posts, which my article borrows from.</li>
<li>Write a custom loss in Keras. Neural nets can be used for large networks with interpretability problems, but we can also use just a single neuron to get linear models with completely custom loss functions.</li>
</ul>
<h2>Summary</h2>
<ul>
<li>The loss that is used during the <code>fit</code> parameter should be thought of as part of the model in scikit-learn. Because of the expense of making function calls, scikit-learn won't be supporting custom losses.</li>
<li>In particular, <code>Ridge</code> and <code>Lasso</code> will always minimize MSE (or equivalently maximize <span class="math">\(R^2\)</span>).</li>
<li>You can minimize MAE using <code>SGDRegressor</code>.</li>
<li>Custom losses require looking outside sklearn (e.g. at Keras) or writing your own estimator.</li>
<li>Model <em>scoring</em> allows you to select between different trained models. Scikit-learn makes custom scoring very easy.</li>
<li>The difference is a custom score is called once per model, while a custom loss would be called thousands of times per model.</li>
<li>The <code>make_scorer</code> documentation unfortunately uses "score" to mean a metric where bigger is better (e.g. <span class="math">\(R^2\)</span>, accuracy, recall, <span class="math">\(F_1\)</span>) and "loss" to mean a metric where smaller is better (e.g. MSE, MAE, log-loss). This usage of loss <em>isn't</em> the same as the way it is used in this article.</li>
</ul>
<h2>References</h2>
<ul>
<li>The <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html"><code>make_scorer</code></a> documentation.</li>
<li>The <a href="https://github.com/scikit-learn/scikit-learn/issues/1701">github issue</a> where the community decided against passing custom loss functions.</li>
<li>Article on implementing a <a href="/custom_loss.html">custom loss</a> (to come)</li>
<li>Alex Miller's <a href="https://alex.miller.im/posts/linear-model-custom-loss-function-regularization-python/">customer estimator</a> for implementing a custom loss (in this case MAPE: Mean Absolute Percentage Error)</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </section>

            <section class="post-info">
                <div class=a"post-share">
                    <a class="twitter" href="https://twitter.com/share?text=Custom Loss vs Custom Scoring&amp;url=https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=https://kiwidamien.github.io/custom-loss-vs-custom-scoring.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="https://kiwidamien.github.io/tag/machine-learning.html">machine learning</a><a href="https://kiwidamien.github.io/tag/technical.html">technical</a><a href="https://kiwidamien.github.io/tag/metrics.html">metrics</a>                </aside>

                <div class="clear"></div>

                <aside class="post-author">
                        <figure class="post-author-avatar">
                            <img src="../assets/images/avatar.png" alt="Damien martin" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="https://kiwidamien.github.io/author/damien-martin.html">Damien martin</a></h4>
                            <p class="post-author-about">I am a data scientist with an interest in what drives the world. Background in Physics, Math, and Computer Science. Interested in Algorithms, Games, Books, Music, and Martial Arts. That is, when I am not off taking pictures somewhere! </p>
                            <span class="post-author-location"><i class="ic ic-location"></i> USA</span>
                            <span class="post-author-website"><a href="http://kiwidamien.github.io"><i class="ic ic-link"></i> Website</a></span>
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <a class="post-nav-prev" href="https://kiwidamien.github.io/changing_definitions.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-right"></i>
                                <h2 class="post-nav-title">Pros and Cons of Changing Definitions</h2>
                            <p class="post-nav-excerpt">A definition cannot be wrong, but it can fail to be useful. Can you repurpose a...</p>
                        </section>
                    </a>
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>
  
  </section>

  <script type="text/javascript" src="https://kiwidamien.github.io/theme/js/script.js"></script>

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-131671634-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>

</html>