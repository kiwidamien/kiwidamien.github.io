<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Webscraping beyond BeautifulSoup and Selenium</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
  <link href="https://kiwidamien.github.io" rel="canonical" />

  <!-- Feed -->

  <link href="https://kiwidamien.github.io/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="https://kiwidamien.github.io/theme/css/code_blocks/monokai.css" rel="stylesheet">
  
  <link href="https://kiwidamien.github.io/theme/css/code_blocks/notebook.css" rel="stylesheet">

    <!-- CSS specified by the user -->
    <link href="https://kiwidamien.github.io/assets/css/mystyle.css" type="text/css" rel="stylesheet" />


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->


    <link href="https://kiwidamien.github.io/webscraping-beyond-beautifulsoup-and-selenium.html" rel="canonical" />

        <meta name="description" content="First article in the advanced web-scraping series. Clarifies the difference between static and dynamic pages. Outlines different...">

        <meta name="author" content="Damien Martin">

        <meta name="tags" content="Scraping">
        <meta name="tags" content="Selenium">
        <meta name="tags" content="BeautifulSoup">

        <meta property="og:locale" content="" />
    <meta property="og:site_name" content="Stacked Turtles" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Stacked Turtles" />
    <meta property="og:description" content="View the blog." />
    <meta property="og:url" content="https://kiwidamien.github.io" />
      <meta property="og:image" content="https://kiwidamien.github.io/assets/images/tools.png" />

  <meta property="og:type" content="article">
            <meta property="article:author" content="https://kiwidamien.github.io/author/damien-martin.html">
  <meta property="og:url" content="https://kiwidamien.github.io/webscraping-beyond-beautifulsoup-and-selenium.html">
  <meta property="og:title" content="Webscraping beyond BeautifulSoup and Selenium">
  <meta property="article:published_time" content="2018-10-15 19:00:00-07:00">
            <meta property="og:description" content="First article in the advanced web-scraping series. Clarifies the difference between static and dynamic pages. Outlines different...">

            <meta propery="og:image" content="https://kiwidamien.github.io/assets/images/cover_background/web_background.svg">
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>
          <li><a href="https://kiwidamien.github.io/about.html" role="presentation">About this blog</a></li>
          <li><a href="http://slashdot.org" role="presentation">slashdot</a></li>
          <li><a href="https://thisismetis.com" role="presentation">metis</a></li>
          <li><a href="https://stackoverflow.com" role="presentation">stackoverflow</a></li>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="https://kiwidamien.github.io" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Webscraping beyond BeautifulSoup and Selenium</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="https://kiwidamien.github.io/author/damien-martin.html">Damien martin</a>
            | <time datetime="Mon 15 October 2018">Mon 15 October 2018</time>
        </span>
        <span class="post-meta">
          Filed under: <b><a href="https://kiwidamien.github.io/category/web.html">Web</a></b>
        </span>

        <!-- TODO : Modified check -->


    <div class="post-cover cover"
      style="background-image: url('assets/images/cover_background/web_background.svg'); background-repeat: repeat; background-size: 100px 100px; background-color: rgb(240,180,82);">
      <div class="logoimg">
        <img src='https://kiwidamien.github.io/assets/images/icon/turtle.svg'/>
      </div>
      <div class="logoimg">
        <img src='assets/images/icon/web_icon.png'/>
      </div>

</div>
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
		    <p>This post is part 1 of the "Advanced Scraping" series:</p>
    		    <ol class="parts">
            	        <li class="active">
                          <a href='https://kiwidamien.github.io/webscraping-beyond-beautifulsoup-and-selenium.html'>Webscraping beyond BeautifulSoup and Selenium</a>
                        </li>
            	        <li >
                          <a href='https://kiwidamien.github.io/using-api-calls-via-the-network-panel.html'>Using API calls via the Network Panel</a>
                        </li>
                    </ol>
                <h1>Static vs Dynamic</h1>
<p>The Python documentation, wikipedia, and most blogs (including this one) use <em>static content</em>. When we request the URL, we get the final HTML returned to us. If that's the case, then a parser like BeautifulSoup is all you need. A short example of scraping a static page is demonstrated below. I have an overview of BeautifulSoup <a href="#todo">here</a>.</p>
<p>A site with <em>dynamic content</em> is one where requesting the URL returns an incomplete HTML. The HTML includes Javascript for the browser to execute. Only once the Javascript finishes running is the HTML in its final state. This is common for sites that update frequently. For example, <a href="http://weather.com">weather.com</a> would use Javascript to look up the latest weather. An Amazon webpage would use Javascript to load the latest reviews from its database. If you use a parser on a dynamically generated page, you get a skeleton of the page with the unexecuted javascript on it.</p>
<p>This post will outline different strategies for scraping dynamic pages.</p>
<h2>An example of scraping a static page</h2>
<p>Let's start with an example of scraping a static page. This code demonstrates how to get the Introduction section of the Python style guide, <a href="https://www.python.org/dev/peps/pep-0008/">PEP8</a>:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>   <span class="c1"># install with &#39;pip install BeautifulSoup4&#39;</span>


<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://www.python.org/dev/peps/pep-0008/&#39;</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

<span class="c1"># By inspecting the HTML in our browser, we find the introduction</span>
<span class="c1"># is contained in &lt;div id=&#39;introduction&#39;&gt; ..... &lt;/div&gt;</span>
<span class="n">intro_div</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;introduction&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">intro_div</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>


<p>This prints</p>
<blockquote>
<p>Introduction
This document gives coding conventions for the Python code comprising
the standard library in the main Python distribution.  Please see the
companion informational PEP describing style guidelines for the C code
in the C implementation of Python [1].
....</p>
</blockquote>
<p>Volia! If all you have is a static page, you are done!</p>
<h2>The straightforward way to scrape a dynamic page</h2>
<p>The easiest way of scraping a dynamic page is to actually execute the javascript, and allow it to alter the HTML to finish the page. We can pass the rendered (i.e. finalized) HTML to python, and use the same parsing techniques we used on static sites. The Python module <a href="https://www.seleniumhq.org/">Selenium</a> allows us to control a browser directly from Python. The steps to Parse a dynamic page using Selenium are:</p>
<ol>
<li>Initialize a <em>driver</em> (a Python object that controls a browser window)</li>
<li>Direct the driver to the URL we want to scrape.</li>
<li>Wait for the driver to finish executing the javascript, and changing the HTML. The driver is typically a Chrome driver, so the page is treated the same way as if you were visiting it in Chrome.</li>
<li>Use <code>driver.page_source</code> to get the HTML as it appears after javascript has rendered it.</li>
<li>Use a parser on the returned HTML</li>
</ol>
<p>The website https://webscraper.io has some fake pages to test scraping on. Let's use it on the page https://www.webscraper.io/test-sites/e-commerce/ajax/computers/laptops to get the product name and the price for the six items listed on the first page. These are randomly generated; at the time of writing the products were an Asus VivoBook (295.99), two Prestigio SmartBs (299 each), an Acer Aspire ES1 (306.99), and two Lenovo V110s (322 and 356).</p>
<p><img alt="Example e-commerce page for scraping practice" src="/images/scraping/e-commerce-example2.png"></p>
<p>Once the HTML has been by Selenium, each item has a div with class <code>caption</code> that contains the information we want. The product name is in a subdiv with class <code>title</code>, and the price is in a subdiv with the classes <code>pull-right</code> and <code>price</code>. Here is code for scraping the product names and prices:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://www.webscraper.io/test-sites/e-commerce/ajax/computers/laptops&#39;</span>

<span class="c1"># Change argument to the location you installed the chrome driver</span>
<span class="c1"># (see selenium installation instructions, or get the driver for your</span>
<span class="c1"># system from https://sites.google.com/a/chromium.org/chromedriver/downloads)</span>
<span class="n">driver</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Chrome</span><span class="p">(</span><span class="s1">&#39;/Users/damien/Applications/chromedriver&#39;</span><span class="p">)</span>
<span class="n">driver</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="c1"># Give the javascript time to render</span>
<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Now we have the page, let BeautifulSoup do the rest!</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">driver</span><span class="o">.</span><span class="n">page_source</span><span class="p">)</span>

<span class="c1"># The text containing title and price are in a</span>
<span class="c1"># div with class caption.</span>
<span class="k">for</span> <span class="n">caption</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s1">&#39;caption&#39;</span><span class="p">):</span>
    <span class="n">product_name</span> <span class="o">=</span> <span class="n">caption</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s1">&#39;title&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="n">price</span> <span class="o">=</span> <span class="n">caption</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s1">&#39;pull-right price&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="k">print</span><span class="p">(</span><span class="n">product_name</span><span class="p">,</span> <span class="n">price</span><span class="p">)</span>
</pre></div>


<h2>Trying scraping a dynamic site using requests</h2>
<p>What would happen if we tried to load this e-commerce site using requests? That is, what if we didn't know it was a dynamic site?</p>
<p>The html we get out can be a little difficult to read directly. If you are using a terminal, then you can save the results from <code>r.html</code> to a file and then load it in a browser. If you are using a Jupyter notebook, you can actually use a neat trick to render the output in your browser:</p>
<div class="highlight"><pre><span></span><span class="c1"># We will try and render what requests returns from https://www.webscraper.io/test-sites/e-commerce/allinone</span>
<span class="c1"># without running javascript first</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://www.webscraper.io/test-sites/e-commerce/ajax/computers/laptops&#39;</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">HTML</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>


<p>The output in the notebook is an empty list, because javascript hasn't generated the items yet.</p>
<p><img alt="Where have all the computers gone?" src="/images/scraping/where-are-the-computers.png"></p>
<h1>Alternatives to Selenium</h1>
<p>Using Selenium is an (almost) sure-fire way of being able to generate any of the dynamic content that you need, because the pages are actually visited by a browser (albeit one controlled by Python rather than you).  If you can see it while browsing, Selenium will be able to see it as well.</p>
<p>There are some drawbacks to using Selenium over pure requests:</p>
<ul>
<li><strong>It's slow.</strong></li>
</ul>
<p>We have to wait for pages to render, rather than just grabbing the data we want.</p>
<ul>
<li><strong>We have to download images and assets, using bandwidth</strong></li>
</ul>
<p>Related to the previous point, even if we are just parsing for text, our browser will download all ads and images on the site.</p>
<ul>
<li><strong>Chrome takes a lot of memory</strong></li>
</ul>
<p>When scraping, we might want to have parallel scrapers running (e.g. one for each category of items on an e-commerce site) to allow us to finish faster. If we use Selenium, we will have to have enough memory to have multiple copies running.</p>
<ul>
<li><strong>We might not need to parse</strong></li>
</ul>
<p>Often sites will make API calls to get the data in a nicely formatted JSON object, which is then processed by Javascript into HTML entities. When using a parser such as BeautifulSoup, we are reading in the HTML entities, and trying to reconstruct the original data. It would be a lot slicker (and less error prone) if we are able to get the JSON objects directly.</p>
<ul>
<li><strong>Selenium (like parsing) is often tedious and error-prone</strong></li>
</ul>
<p>The bad news for using the alternative methods is that there are so many different ways of loading data that no single technique is guaranteed to work. The biggest advantage Selenium has is that it uses a browser, and with enough care, should be indistinguishable from you browsing the web yourself.</p>
<h2>Other techniques</h2>
<p>This is the first in a series of articles that will look at other techniques to get data from dynamic webpages. Because scraping requires a custom approach to each site we scrape, each technique will be presented as a case study. The examples will be detailed enough to enable you to try the technique on other sites.</p>
<table>
<thead>
<tr>
<th>Technique</th>
<th>Description</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scheme or Opengraph MetaData</td>
<td>OpenGraph is a standard for allowing sites like Facebook to easily find what your page is 'about'. We can scrape the relevant data directly from these tags</td>
<td>??? Need example ???</td>
</tr>
<tr>
<td>JSON for Linking Data</td>
<td>This is a standard for putting JSON inside Javascript tags</td>
<td>Yelp</td>
</tr>
<tr>
<td>XHR</td>
<td>Use the same API requests that the browser does to get the data</td>
<td>Sephora lipsticks, Apple jobs</td>
</tr>
</tbody>
</table>
<h2>Selenium summary</h2>
<p>The short list of pros and cons for using Selenium to scrape dynamic sites.</p>
<table>
<thead>
<tr>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td>* Will work</td>
<td>* Slow</td>
</tr>
<tr>
<td></td>
<td>* Bandwidth and memory intensive</td>
</tr>
<tr>
<td></td>
<td>* Requires error-prone parsing</td>
</tr>
</tbody>
</table>
            </section>

            <section class="post-info">
                <div class=a"post-share">
                    <a class="twitter" href="https://twitter.com/share?text=Webscraping beyond BeautifulSoup and Selenium&amp;url=https://kiwidamien.github.io/webscraping-beyond-beautifulsoup-and-selenium.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://kiwidamien.github.io/webscraping-beyond-beautifulsoup-and-selenium.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=https://kiwidamien.github.io/webscraping-beyond-beautifulsoup-and-selenium.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="https://kiwidamien.github.io/tag/scraping.html">Scraping</a><a href="https://kiwidamien.github.io/tag/selenium.html">Selenium</a><a href="https://kiwidamien.github.io/tag/beautifulsoup.html">BeautifulSoup</a>                </aside>

                <div class="clear"></div>

                <aside class="post-author">
                        <figure class="post-author-avatar">
                            <img src="../assets/images/avatar.png" alt="Damien martin" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="https://kiwidamien.github.io/author/damien-martin.html">Damien martin</a></h4>
                            <p class="post-author-about">I am a data scientist with an interest in what drives the world. Background in Physics, Math, and Computer Science. Interested in Algorithms, Games, Books, Music, and Martial Arts. That is, when I am not off taking pictures somewhere! </p>
                            <span class="post-author-location"><i class="ic ic-location"></i> USA</span>
                            <span class="post-author-website"><a href="http://kiwidamien.github.io"><i class="ic ic-link"></i> Website</a></span>
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <a class="post-nav-next" href="https://kiwidamien.github.io/using-api-calls-via-the-network-panel.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-left"></i>
                                <h2 class="post-nav-title">Using API calls via the Network Panel</h2>
                            <p class="post-nav-excerpt">Second article in the advanced web-scraping series. Clarifies the difference between...</p>
                        </section>
                    </a>
                    <a class="post-nav-prev" href="https://kiwidamien.github.io/getting-data-with-oauth.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-right"></i>
                                <h2 class="post-nav-title">Getting data with OAuth</h2>
                            <p class="post-nav-excerpt">An example of using OAuth2.0 to access an API using Python's requests module, using...</p>
                        </section>
                    </a>
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>
  
  </section>

  <script type="text/javascript" src="https://kiwidamien.github.io/theme/js/script.js"></script>

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-131671634-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>

</html>