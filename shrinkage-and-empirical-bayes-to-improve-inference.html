<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Shrinkage and Empirical Bayes to improve inference</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
  <link href="https://kiwidamien.github.io" rel="canonical" />

  <!-- Feed -->

  <link href="https://kiwidamien.github.io/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="https://kiwidamien.github.io/theme/css/code_blocks/monokai.css" rel="stylesheet">

    <!-- CSS specified by the user -->
    <link href="https://kiwidamien.github.io/assets/css/mystyle.css" type="text/css" rel="stylesheet" />

  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->


    <link href="https://kiwidamien.github.io/shrinkage-and-empirical-bayes-to-improve-inference.html" rel="canonical" />

        <meta name="description" content="The highest and lowest rated books, films, and music are those that have very few ratings. This is because for small samples, it is...">

        <meta name="author" content="Damien Martin">

        <meta name="tags" content="data">
        <meta name="tags" content="statistics">
        <meta name="tags" content="Bayes">
        <meta name="tags" content="shrinkage">

        <meta property="og:locale" content="" />
    <meta property="og:site_name" content="Stacked Turtles" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Stacked Turtles" />
    <meta property="og:description" content="View the blog." />
    <meta property="og:url" content="https://kiwidamien.github.io" />
      <meta property="og:image" content="https://kiwidamien.github.io/assets/images/tools.png" />

  <meta property="og:type" content="article">
            <meta property="article:author" content="https://kiwidamien.github.io/author/damien-martin.html">
  <meta property="og:url" content="https://kiwidamien.github.io/shrinkage-and-empirical-bayes-to-improve-inference.html">
  <meta property="og:title" content="Shrinkage and Empirical Bayes to improve inference">
  <meta property="article:published_time" content="2018-12-26 15:00:00-08:00">
            <meta property="og:description" content="The highest and lowest rated books, films, and music are those that have very few ratings. This is because for small samples, it is...">

            <meta property="og:image" content="https://kiwidamien.github.io/assets/images/tools.png">
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>
          <li><a href="https://kiwidamien.github.io/about.html" role="presentation">About this blog</a></li>
          <li><a href="http://slashdot.org" role="presentation">slashdot</a></li>
          <li><a href="https://thisismetis.com" role="presentation">metis</a></li>
          <li><a href="https://stackoverflow.com" role="presentation">stackoverflow</a></li>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="https://kiwidamien.github.io" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Shrinkage and Empirical Bayes to improve inference</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="https://kiwidamien.github.io/author/damien-martin.html">Damien martin</a>
            | <time datetime="Wed 26 December 2018">Wed 26 December 2018</time>
        </span>
        <span class="post-meta">
          Filed under: <b><a href="https://kiwidamien.github.io/category/data-science.html">Data science</a></b>
        </span>

        <!-- TODO : Modified check -->


    <div class="post-cover cover" style="background-image: url('assets/images/tools.png')">

</div>
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
		    <p>This post is part 1 of the "Empirical Bayes" series:</p>
    		    <ol class="parts">
            	        <li class="active">
                          <a href='https://kiwidamien.github.io/shrinkage-and-empirical-bayes-to-improve-inference.html'>Shrinkage and Empirical Bayes to improve inference</a>
                        </li>
            	        <li >
                          <a href='https://kiwidamien.github.io/empirical-bayes-with-regression.html'>Empirical Bayes with regression</a>
                        </li>
            	        <li >
                          <a href='https://kiwidamien.github.io/derivations-and-conjugate-priors.html'>Derivations and Conjugate Priors</a>
                        </li>
                    </ol>
                <h1>Shrinkage and Empirical Bayes to improve inference</h1>
<p>There is a common problem when ranking items: if we just average the observations, fluctuations tend to make the very best (and very worst) items be those with very few observations. Consider the following three examples:</p>
<ul>
<li>We are trying to measure the batters with the best hit rate. A rookie that has hit 2 balls out of 2 at-bats would have a hit rate of 1.0, handily beating Barry Bond's career hit rate of 0.306. To get hit rates over 0.300 is rare in major league baseball, so we are confident that the rookie's actual hit rate isn't 1.000.</li>
<li>When looking at kidney cancer incidence rates per county. It is a relatively rare disease, with the bottom rate being 6.6 per 100k in Garfield County (4 out of 60000), and a highest rate of 41.1 per 100k in Cass County (7 out of 17000). Having just one fewer person diagnosed with kidney cancer in Cass County would drop the rate to 35.2 per 100k. There are 63 counties that where the 95% confidence interval in the rate exceeds 41.1 per 100k.</li>
<li>We are trying to measure the rating of a book. A book with two 5 star ratings probably isn't better than a book with ten thousand ratings that average to 4.85.</li>
</ul>
<p>In each of these cases, just measuring the average over all items isn't useful. We want to know what the hit rate is of an individual player, the counties that have abnormally high kidney cancer rates, or the our best estimate of the actual book. One way of approaching this would be to have a cutoff and refuse to make any inference before we had "enough" data.</p>
<p>Empirical Bayes approaches this problem differently. We use the entire population (that is, all players, all counties, or all books) to estimate what a "typical" result looks like. If we had no batting data, for example, we can still say based on all major league players that a given player is likely to have a hit rate between 0.2 and 0.3. We use this as the <em>prior</em>. This is the <em>empirical</em> part.  As we collect more and more data, we use Bayes's rule to update our prior. When we have only a little bit of data on a player, county, or book, the prior is important for keeping our estimates grounded. As we get more data, the initial prior becomes less and less important, which matches our intuition that the large fluctuations needed to significantly bias large datasets are rare.</p>
<p>This general technique of moving the observed data toward the mean is also called "shrinkage" (although maybe "regression", as in "regression to the mean" would be a better name).</p>
<p>David Robinson has already given an <a href="http://varianceexplained.org/r/empirical_bayes_baseball/">excellent treatment</a> of empirical Bayes in the context of baseball statistics on his blog, <a href="http://varianceexplained.org/">variance explained</a>. We will look at the two other examples above in this blog post:</p>
<ul>
<li>We will look at the kidney cancer rates per county. This example has been discussed in "Thinking Fast and Slow" by Daniel Kahneman. The data set is available <a href="http://statecancerprofiles.cancer.gov/map/map.withimage.php?99&amp;001&amp;072&amp;00&amp;0&amp;01&amp;0&amp;1&amp;6&amp;0#results">here</a></li>
<li>We will look at the ratings of boardgames given at boardgamegeek. This problem was inspired by the 538 article <a href="https://fivethirtyeight.com/features/the-worst-board-games-ever-invented/">"Worst board game ever invented"</a>. In this case, the ratings were not shrunk, so games with fewer reviews typically showed more variance. The data set for this problem is available <a href="https://github.com/rasmusgreve/BoardGameGeek/blob/master/DataMining/data2014-04-03_03-35-14.csv">here</a>.</li>
</ul>
<p>By using these two examples, we can show how to apply the empirical Bayes's technique of "shrinking" (or regressing) our observed values toward the mean when estimating a proportion (kidney cancer rates) as well as a continuous variable (board game ratings).</p>
<p><strong>NOTES</strong>
1. This notebook is mostly written to expose the reader to the idea of shrinkage, and be able to apply it quickly. For that reason, code is included but the derivations are not. The derivations of the formula are available in a <a href="/derivations-and-conjugate-priors.html">more detailed article</a>.
2. Data and the notebooks are available <a href="https://github.com/kiwidamien/StackedTurtles/tree/master/projects/empirical_bayes">here</a>.</p>
<h2>Case study 1: Shrinking proportions with kidney cancer data</h2>
<p>Let's start by getting an overall view of the kidney cancer rates. Our first attempt might be to simply make a histogram of the kidney cancer rate.</p>
<p><img src='images/kidney/beta_distribution_nofit.png' alt='Histogram of cancer rates per county' style="width:80%; margin: 0 auto;"/></p>
<p>It is relatively simple to identify the lowest and highest observed rates directly from the histogram. But by displaying this data as a histogram, we haven't displayed the sample size of each county, so it isn't clear how reliable each of the individual measurements are. The story looks very different once we add population size as an axis. The overall average rate (as measured over the entire US) is shown as a dashed line.</p>
<p><img src='images/kidney/rate_vs_pop_raw.png' alt='Raw rates versus population size' style="width:80%; margin: 0 auto;"/></p>
<p>We see that there is a lot more variation in cancer rates for the counties with small populations, with the variation getting smaller as we go to larger counties. This is the type of behavior we expect from statistical fluctuations!</p>
<h3>Overview of method</h3>
<p>We are going to assume that each county <span class="math">\(i\)</span> is described by a kidney cancer rate, <span class="math">\(p_i\)</span>. The <span class="math">\(p_i\)</span> are randomly distributed according to the histogram of kidney cancer rates we plotted earlier. That is, if we had a probability distribution that matched the shape of this histogram, we could tell how likely it was that a particular cancer rate <span class="math">\(p_i\)</span> was observed.</p>
<p>It is convenient if we can model this process using a <span class="math">\(\beta\)</span>-distribution. The <span class="math">\(\beta\)</span> distribution is described by two parameters, <code>s0</code> and <code>f0</code>, which we can think of as "banked" successes and failures. If we observe <code>s_i</code> actual sick people in a county, and <code>f_i</code> healthy people in the county, then the naive calculation for the rate people are getting sick is
</p>
<div class="math">$$ p_i = \frac{\text{num actually sick}}{\text{total actual people}} = \frac{s_i}{s_i + f_i} $$</div>
<p>The empirical Bayes method would adjust this estimate to
</p>
<div class="math">$$ p_i = \frac{s_i + s_0}{s_i + f_i + (s_0 + f_0)} $$</div>
<p>One way of thinking about this result is that we are pretending that we have <code>s0</code> sick people and <code>f0</code> healthy people that are not actually part of our population. When calculating the rate, we still look at the ratio of sick people to the total, but we also include the <code>(s0 + f0)</code> "imaginary people" we are using to represent the rest of the population.</p>
<h3>Step 1: Use population data to get prior</h3>
<p>Since we are modeling a binomial process (in each county, an individual either does or does not get sick), it is convenient if we can model this distribution with a <span class="math">\(\beta\)</span>-distribution. One way of doing this is called the "method of moments", where we find <code>s0</code> and <code>f0</code> to make the mean and variance of the beta distribution match the mean and variance of our data. The formula are</p>
<div class="math">$$
s_0 = \mu\left(\frac{\mu(1-\mu)}{s^2} - 1\right)\\
f_0 = (1-\mu)\left(\frac{\mu(1-\mu)}{s^2} - 1\right) = \frac{(1-\mu)}{\mu}s_0
$$</div>
<p>Instead of trying to match mean and variance, we can use the built-in <code>fit</code> method for finding the parameters:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">beta</span>
<span class="n">s0</span><span class="p">,</span> <span class="n">f0</span><span class="p">,</span> <span class="o">*</span><span class="n">extra_params</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">incidence</span><span class="p">[</span><span class="s1">&#39;Rate_per_100k&#39;</span><span class="p">]</span><span class="o">/</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">floc</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">fscale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
</pre></div>


<p>The values for these parameters are <span class="math">\(s_0=19.4\)</span> and <span class="math">\(f_0=106389\)</span>. That is, for every county we imagine there are an additional 19 sick people, and an additional 106389 healthy people.</p>
<p>We can visualize how well this plot did with the following code, using <code>beta.pdf</code> with our parameters to plot our fitted beta distribution.</p>
<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">130</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">s0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">f0</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Beta dist&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">incidence</span><span class="p">[</span><span class="s1">&#39;Rate_per_100k&#39;</span><span class="p">]</span><span class="o">/</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Best fit beta distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Prob of Kidney Disease&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;PDF&#39;</span><span class="p">);</span>
</pre></div>


<p><img src='images/kidney/beta_distribution_fit.png' alt='Histogram of cancer rates per county' style="width:80%; margin: 0 auto;"/></p>
<p>The fit isn't terrible, but a slightly smaller lump around 0.00023 suggests we might have two different mixed beta distributions. We could improve the fit slightly by modeling our prior as two beta distributions, but this would complicate our shrinkage. We still find a reasonable fit with <code>s0</code> and <code>f0</code>.</p>
<p>The downside to using the best-fit method is that the average rate is shrunk toward the average of the beta distribution, not the average of the data. We can find the average of the beta distribution directly from the parameters <code>s0</code> and <code>f0</code>:
</p>
<div class="math">$$\text{average of beta distribution} = \frac{s_0}{s_0 + f_0} = 0.000182 \text{ (i.e. 18.2 per 100k)}$$</div>
<p>
By comparison, the average from the data is 16.1 per 100k.</p>
<h3>Step 2: Use prior to "shrink" estimates to population values</h3>
<p>Our dataframe <code>incidence</code> has the following columns:</p>
<ul>
<li><code>'average_annual_count'</code>: the number of people in the county that we found the disease.</li>
<li><code>'population'</code>: the population of the people in the country.</li>
</ul>
<p>To get our empirical Bayes estimate needs us to add <code>s0</code> to the number of detected cases, and <code>s0 + f0</code> to the population. Recalling that we are reporting rates per 1e5 people, the calculation for the corrected column is simple:</p>
<div class="highlight"><pre><span></span><span class="n">incidence</span><span class="p">[</span><span class="s1">&#39;shrinkage&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e5</span><span class="o">*</span><span class="p">(</span><span class="n">incidence</span><span class="p">[</span><span class="s1">&#39;average_annual_count&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">s0</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">incidence</span><span class="p">[</span><span class="s1">&#39;population&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">s0</span> <span class="o">+</span> <span class="n">f0</span><span class="p">)</span>
</pre></div>


<p>Let's compare what the rates looked like before and after the shrinkage. We recreate the plot of cancer rate vs population. Note the shrinkage effect is much larger for the smaller populations. We also show the dashed line that we shrink toward (approx 18 per 100k), as well as the average of the actual data as the dotted line (approx 16 per 100k).</p>
<p><img src='images/kidney/rate_vs_pop_shrunk.png' alt='Histogram of cancer rates per county' style="width:80%; margin: 0 auto;"/></p>
<p>Now that we have our best estimate based on the sample size, we can plot a histogram of the  adjusted rate.</p>
<p><img src='images/kidney/histograms.png' alt='Histogram of cancer rates per county' style="width:80%; margin: 0 auto;"/></p>
<h2>Case study 2: Shrinking continuous data with board game ratings</h2>
<p>This time, we will look at correcting the average of a continuous variable, instead of a rate. The website <a href="http://boardgamegeek.com">BoardGameGeek</a> collects user and critic ratings of many different board games. If we look at the average rating of each game with more than 30 ratings, we get the following histogram</p>
<p><img src='images/boardgames/raw_dist.png' alt='Histogram of raw user ratings (from Boardgamegeek.com)' style="width:80%; margin: 0 auto;"/></p>
<p>(Games with very few ratings tend to concentrate around integer and half-integer ratings, which puts visual "spikes" in the histogram.)</p>
<p>After the previous discussion, might be wondering how confident we are in the extreme ends of the distribution. We would expect that the games with few reviews would have an easier time getting a very high or very low review score. Let's check this intuition by plotting review score against the number of reviews.</p>
<p><img src='images/boardgames/rating_vs_popularity_raw.png' alt='Review ratings vs number of reviews' style="width:80%; margin: 0 auto;"/></p>
<p>Once again we see the "triangle shape" indicating that the tails of the distribution are dominated by the data we are least confident in. Since we are modeling sample means (i.e. the average rating given to a board game by the users), the central limit theorem tells us that the sample means will be normally distributed around the true mean.</p>
<p>We also note that there is some bias in the results: instead of the distribution just narrowing down as the game becomes more popular, there is a fairly distinct upward rise in average ratings as the game becomes more popular. We will address this in a more <a href="/empirical-bayes-with-regression.html">detailed article</a> on empirical Bayes with regression; in this article we will just take a naive approach.</p>
<p>Our distribution above suggests we won't go too far wrong by taking the distribution <em>actual</em> game scores to be normally distributed. Yes, the logic here isn't completely airtight -- we are using the distribution of <em>sample</em> means to infer the distribution of <em>actual</em> means -- but this is the "empirical" part of empirical Bayes!</p>
<h3>Some notation</h3>
<p>Before breaking down the methodology, we should introduce some notation. First we have some global parameters, which describe the distribution of game ratings:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">\(\mu\)</span></td>
<td>The average score of all board games (i.e. the average in the histogram above)</td>
</tr>
<tr>
<td><span class="math">\(\tau^2\)</span></td>
<td>The variance in ratings of all board games (i.e. the variance in the histogram above)</td>
</tr>
</tbody>
</table>
<p>We also have parameters on a per game basis. Since the dataframe <code>games</code> has one row per game, with summary statistics, and not the individual reviews, we include the column name used in the <a href="https://github.com/kiwidamien/StackedTurtles/blob/master/projects/empirical_bayes/empirical_board_game.ipynb">code</a></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Meaning</th>
<th>Column name</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math">\(\theta_i\)</span></td>
<td>The actual (unknown) rating of the game <span class="math">\(i\)</span></td>
<td>(not available)</td>
</tr>
<tr>
<td><span class="math">\(\bar{x}_i\)</span></td>
<td>The average measured rating of game <span class="math">\(i\)</span> (i.e. the naive average rating per game)</td>
<td><code>'average_rating'</code></td>
</tr>
<tr>
<td><span class="math">\(\sigma_i^2\)</span></td>
<td>The variance in the ratings of game <span class="math">\(i\)</span></td>
<td><code>'rating_stddev'</code></td>
</tr>
<tr>
<td><span class="math">\(n_i\)</span></td>
<td>The number of reviews for game <span class="math">\(i\)</span></td>
<td><code>'users_rated'</code></td>
</tr>
<tr>
<td><span class="math">\(\epsilon_i^2\)</span></td>
<td>The standard error in the rating of game <span class="math">\(i\)</span>, which is <span class="math">\(\sigma_i^2/n_i\)</span></td>
<td>(calculated)</td>
</tr>
</tbody>
</table>
<h3>Step 1: Calculate the population parameters</h3>
<p>We can estimate the population mean and variance directly from the series <code>'average_rating'</code>. In this example, I did it the lazy way:</p>
<div class="highlight"><pre><span></span><span class="n">MIN_REVIEWS</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">subset_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">games</span><span class="p">[</span><span class="s1">&#39;average_rating&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">MIN_REVIEW</span><span class="p">)</span>
<span class="n">rating_masked</span> <span class="o">=</span> <span class="n">games</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subset_mask</span><span class="p">,</span> <span class="s1">&#39;average_rating&#39;</span><span class="p">]</span>

<span class="c1"># This is our population mean</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">rating_masked</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="c1"># This is our population variance</span>
<span class="n">tau2</span> <span class="o">=</span> <span class="n">rating_masked</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
</pre></div>


<p>The less lazy way of doing it would be to take a weighted average and a pooled variance, so that games with more reviews influenced the population mean more. The above method is a nice to get a quick-and-dirty estimate.</p>
<h3>Step 2: Get the standard error</h3>
<p>This uses the central limit theorem (CLT) to estimate the error we have in the estimate of the mean on a per game basis. The CLT tells us that the sample mean (i.e. our measurement ) will be drawn from a normal distribution around the true (unobserved) mean <span class="math">\(\theta_i\)</span> and variance <span class="math">\(\epsilon_i^2 = \sigma_i^2 / n_i\)</span>. In code:</p>
<div class="highlight"><pre><span></span><span class="c1"># These are our epsilon_i^2</span>
<span class="n">games</span><span class="p">[</span><span class="s1">&#39;std_var&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">games</span><span class="p">[</span><span class="s1">&#39;rating_stddev&#39;</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">games</span><span class="p">[</span><span class="s1">&#39;users_rated&#39;</span><span class="p">]</span>
</pre></div>


<h3>Step 3: Calculate the interpolation factor</h3>
<p>For each game, we have to weigh how much of the rating comes from the observed rating for that game, and how much comes from the overall population. The following factor, <span class="math">\(B_i\)</span>, does this for us:
</p>
<div class="math">$$B_i = \frac{\tau^2}{\tau^2 + \epsilon_i^2}$$</div>
<p>If we have a lot of ratings for a game, and the variance in the ratings for that game are low, we have <span class="math">\(\epslion_i^2 \ll \tau^2\)</span>, so <span class="math">\(B_i \approx 1\)</span>. When <span class="math">\(B_i\)</span> is close to 1, we expect most of the contribution to come from the ratings on the game.</p>
<p>On the other hand, if we have relatively little information on the game, <span class="math">\(\epsilon_i^2 \gg \tau^2\)</span>, so <span class="math">\(B_i \approx 0\)</span>. This is where we would expect the global average to be important.</p>
<p>We will see in step 4 that this intuition holds. In our <a href="/derivations-and-conjugate-priors.html">derivation article</a> we will show where this formula comes from, but at the moment it is enough to gain an intuition of what <span class="math">\(B_i\)</span> close to its two extremes means.</p>
<p>To calculate this factor in code is simple:</p>
<div class="highlight"><pre><span></span><span class="n">games</span><span class="p">[</span><span class="s1">&#39;interpolation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau2</span> <span class="o">/</span> <span class="p">(</span><span class="n">tau2</span> <span class="o">+</span> <span class="n">games</span><span class="p">[</span><span class="s1">&#39;std_var&#39;</span><span class="p">])</span>
</pre></div>


<h3>Step 4: Regress/Shrink the measured value</h3>
<p>We can use the interpolation factor in the previous step with the following formula:
</p>
<div class="math">$$\text{shrunk rating} = B_i \bar{x}_i + (1 - B_i) \mu$$</div>
<p>In code, this is</p>
<div class="highlight"><pre><span></span><span class="n">games</span><span class="p">[</span><span class="s1">&#39;shrunk_rating&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">games</span><span class="p">[</span><span class="s1">&#39;interpolation&#39;</span><span class="p">]</span><span class="o">*</span><span class="n">games</span><span class="p">[</span><span class="s1">&#39;average_rating&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">games</span><span class="p">[</span><span class="s1">&#39;interpolation&#39;</span><span class="p">])</span><span class="o">*</span><span class="n">mu</span>
</pre></div>


<p>That's it -- we are done!</p>
<p>Here is the plot of the ratings vs population size, showing the distributions both before and after applying shrinkage.</p>
<p><img src='images/boardgames/rating_vs_popularity_shrunk.png' alt='Review ratings vs number of reviews' style="width:80%; margin: 0 auto;"/></p>
<h2>Summary</h2>
<p>We can do better than looking at an overall average rate or rating, especially when dealing with small sample sizes. We know that it is easier to move an average when there are only a small number of measurements; if we know what the overall distribution of measurements should look like we can correct the small samples. By allowing results to "shrink" (or "regress") to the mean, you make the results for your "best-of" and "worst-of" lists much more stable.</p>
<p>The techniques in this article are most useful for analytics tasks, where you are being asked to generate reports or make insights based on what has already happened. If you are building a machine learning model on average rates, such as trying to predict the factors that influence the cancer rate of a county, you have a couple of different approaches:
<em> Use the techniques in this article, and fit to the "shrunk" estimates
</em> Use the actual measured averages, but introduce a weighting factor so that measurements averaged over fewer observations carry less weight.</p>
<p>This is an important point that can hang up many beginning data scientists, as discussed in Cameron Pilon on his PyData talk <a href="https://www.youtube.com/watch?v=VWtsTIbFXxA&amp;t=91">"Mistakes I've Made"</a>.</p>
<p>This article showed two different techniques for empirical Bayes, one for correcting <em>rates</em> and the other for correcting <em>regression (of averages)</em>.</p>
<h4>Correcting rates</h4>
<ol>
<li>Model the distribution of rates in your data using the beta-distribution. Call these parameters <span class="math">\(s_0\)</span> and <span class="math">\(f_0\)</span>.</li>
<li>For each sample (e.g. county) with <span class="math">\(s\)</span> "successes" and <span class="math">\(f\)</span> "failures", shrink the rate using the following technique:
<div class="math">$$\text{rate} = \frac{s + s_0}{(s + f) + (s_0 + f_0)}$$</div>
</li>
</ol>
<h4>Correcting averages</h4>
<ol>
<li>Model the distribution of averages in your data using the normal distribution. Use the mean <span class="math">\(\mu\)</span> and variance <span class="math">\(\tau^2\)</span> of this distribution.</li>
<li>For each sample (e.g. board game) with an average of <span class="math">\(N_i\)</span> reviews and variance in measurements, <span class="math">\(\sigma_i^2\)</span>, the central limit theorem tells us that our measurement of the mean will have a variance <span class="math">\(\sigma_i^2/N_i\)</span>.</li>
<li>For each sample, define
  <div class="math">$$B_i = \frac{\tau^2}{\tau^2 + (\sigma^2_i/N_i)}$$</div>
  Note that when <span class="math">\(B_i\approx 1\)</span>, we have <span class="math">\(\sigma^2_i/N_i \ll \tau^2\)</span>, meaning that we are much more certain about this measurement than the overall variation in the population, so we expect our measurement to dominate. When <span class="math">\(B_i \approx 0\)</span>, we have <span class="math">\(\sigma^2_i/N_i \gg \tau^2\)</span>, so we expect fluctuations from this single sample to be much bigger than the population standard deviation (so shrinkage will dominate).</li>
<li>The "shrunk" estimate for sample <span class="math">\(i\)</span> is
  <div class="math">$$\text{rating} = B_i \bar{x}_i + (1 - B_i) \mu$$</div>
</li>
</ol>
<p>where <span class="math">\(\bar{x}_i\)</span> is the (raw) measured rating over the <span class="math">\(N_i\)</span> measurements.</p>
<h3>Other resources</h3>
<p>This article hasn't focused on the mathematical derivations, if you are interested a follow up article is <a href="/derivations-and-conjugate-priors.html">here</a>. Another nice resource on empirical Bayes is David Robinson's blog, <a href="http://varianceexplained.org/r/empirical_bayes_baseball/">Variance Explained</a>. A project on when using empirical Bayes it is useful (and when it isn't) in epidemiological studies is available <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2872278/">here</a>.</p>
<p>Finally, the data cleaning and notebooks for this project are available <a href="https://github.com/kiwidamien/StackedTurtles/tree/master/projects/empirical_bayes">here</a>.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </section>

            <section class="post-info">
                <div class=a"post-share">
                    <a class="twitter" href="https://twitter.com/share?text=Shrinkage and Empirical Bayes to improve inference&amp;url=https://kiwidamien.github.io/shrinkage-and-empirical-bayes-to-improve-inference.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://kiwidamien.github.io/shrinkage-and-empirical-bayes-to-improve-inference.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=https://kiwidamien.github.io/shrinkage-and-empirical-bayes-to-improve-inference.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="https://kiwidamien.github.io/tag/data.html">data</a><a href="https://kiwidamien.github.io/tag/statistics.html">statistics</a><a href="https://kiwidamien.github.io/tag/bayes.html">Bayes</a><a href="https://kiwidamien.github.io/tag/shrinkage.html">shrinkage</a>                </aside>

                <div class="clear"></div>

                <aside class="post-author">
                        <figure class="post-author-avatar">
                            <img src="../assets/images/avatar.png" alt="Damien martin" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="https://kiwidamien.github.io/author/damien-martin.html">Damien martin</a></h4>
                            <p class="post-author-about">I am a data scientist with an interest in what drives the world. Background in Physics, Math, and Computer Science. Interested in Algorithms, Games, Books, Music, and Martial Arts. That is, when I am not off taking pictures somewhere! </p>
                            <span class="post-author-location"><i class="ic ic-location"></i> USA</span>
                            <span class="post-author-website"><a href="http://kiwidamien.github.io"><i class="ic ic-link"></i> Website</a></span>
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <a class="post-nav-next" href="https://kiwidamien.github.io/pet-peeve-art-vs-science.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-left"></i>
                                <h2 class="post-nav-title">Pet Peeve - Art vs Science</h2>
                            <p class="post-nav-excerpt">The expression "Data science is more art than science" makes my skin crawl. Data...</p>
                        </section>
                    </a>
                    <a class="post-nav-prev" href="https://kiwidamien.github.io/an-introduction-to-simpleprophet.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-right"></i>
                                <h2 class="post-nav-title">An introduction to SimpleProphet</h2>
                            <p class="post-nav-excerpt">Introduces SimpleProphet, a less automated version of Facebook's time series analysis...</p>
                        </section>
                    </a>
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>
  
  </section>

  <script type="text/javascript" src="https://kiwidamien.github.io/theme/js/script.js"></script>

</body>
</html>